{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, roc_auc_score, log_loss\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score, cross_val_predict, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, scale, StandardScaler, normalize, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.sparse import csc_matrix, coo_matrix, csr_matrix, hstack\n",
    "from scipy.stats.mstats import gmean, hmean\n",
    "from scipy.stats import *\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import product, combinations\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train2.csv')\n",
    "mir_train = train.rename(columns={'team1':'team2', 'team2':'team1', 'score1':'score2', 'score2':'score1'})\n",
    "mir_train['target'] = 1 - mir_train.target\n",
    "train = pd.concat([train, mir_train])\n",
    "train = train.reset_index().sort('index').reset_index().drop(['level_0', 'index'], axis=1)\n",
    "\n",
    "test = pd.read_csv('test2.csv')\n",
    "mir_test = train.rename(columns={'team1':'team2', 'team2':'team1'})\n",
    "mir_test['Id'] = np.nan\n",
    "test = pd.concat([test, mir_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train, test = train[train.year < 3019], train[train.year >= 3019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yearday = sorted(set(zip(train.year, train.day)))\n",
    "e = np.ones(train.shape[0])\n",
    "S_train = csc_matrix((e, (train.index.values, train.team1))) - csc_matrix((e, (train.index.values, train.team2)))\n",
    "e = np.ones(test.shape[0])\n",
    "S_test = csc_matrix((e, (np.arange(test.shape[0]), test.team1))) - csc_matrix((e, (np.arange(test.shape[0]), test.team2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_slice(sparse_df, df, y, yearday1, yearday2):\n",
    "    ind1 = min(np.where(np.logical_and(df.year >= yearday1[0], df.day >= yearday1[1]))[0])\n",
    "    ind2 = max(np.where(np.logical_and(df.year <= yearday2[0], df.day <= yearday2[1]))[0])\n",
    "    return sparse_df[ind1:ind2], y[ind1:ind2]\n",
    "\n",
    "def get_ind(df, yearday):\n",
    "    ind = np.logical_and(df.year == yearday[0], df.day == yearday[1])\n",
    "    return ind.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "train['logreg'] = 0\n",
    "lr = LogisticRegression(C=0.06)\n",
    "for i in range(len(yearday) - n - 1):\n",
    "    X_, y_ = get_slice(S_train, train, train.target.values, yearday[i], yearday[i + n])\n",
    "    lr.fit(X_, y_)\n",
    "    ind = get_ind(train, yearday[i + n + 1])\n",
    "    pred = lr.predict_proba(S_train[ind])\n",
    "    train.loc[ind, 'logreg'] = pred[:,1]\n",
    "    if i % 100 == 0: print i,\n",
    "X_, y_ = get_slice(S_train, train, train.target.values, yearday[len(yearday) - n - 1], yearday[len(yearday) - 1])\n",
    "lr.fit(X_, y_)\n",
    "pred = lr.predict_proba(S_test)\n",
    "test['logreg'] = pred[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "train['linreg'] = 0\n",
    "lr = LinearRegression(fit_intercept=0)\n",
    "for i in range(len(yearday) - n - 1):\n",
    "    X_, y_ = get_slice(S_train, train, train.score1.values - train.score2.values, yearday[i], yearday[i + n])\n",
    "    lr.fit(X_, y_)\n",
    "    ind = get_ind(train, yearday[i + n + 1])\n",
    "    pred = lr.predict(S_train[ind])\n",
    "    train.loc[ind, 'linreg'] = pred\n",
    "    if i % 100 == 0: print i,\n",
    "X_, y_ = get_slice(S_train, train, train.target.values, yearday[len(yearday) - n - 1], yearday[len(yearday) - 1])\n",
    "lr.fit(X_, y_)\n",
    "pred = lr.predict(S_test)\n",
    "test['linreg'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def history_rating(team1_train, team2_train, target, team1_test, team2_test, gamma=0.1):\n",
    "    teams = list(set(zip(team1_train, team2_train)))\n",
    "    d = dict(zip(teams, np.zeros(len(teams))))\n",
    "    w1, w2 = [], []\n",
    "    for t1, t2, y in zip(team1_train, team2_train, target):\n",
    "        w1.append(0.5 + d[(t1, t2)])\n",
    "        w2.append(0.5 + d[(t2, t1)])\n",
    "        d[(t1, t2)] += d[(t1, t2)]*gamma + y\n",
    "    w1, w2 = np.array(w1), np.array(w2)\n",
    "    \n",
    "    w1_, w2_ = [], []\n",
    "    for t1, t2 in zip(test.team1, test.team2):\n",
    "        if (t1, t2) in d:\n",
    "            w1_.append(0.5 + d[(t1, t2)])\n",
    "            w2_.append(0.5 + d[(t2, t1)])\n",
    "        else:\n",
    "            w1_.append(0.5)\n",
    "            w2_.append(0.5)\n",
    "    w1_, w2_ = np.array(w1_), np.array(w2_)\n",
    "    return w1, w2, w1_, w2_\n",
    "\n",
    "def win_mean(team_train, target, team_test, gamma=0.1):\n",
    "    teams = list(set(team_train))\n",
    "    d = dict(zip(teams, np.zeros(len(teams))))\n",
    "    w, w_ = [], []\n",
    "    for t, y in zip(team_train, target):\n",
    "        w.append(d[t])\n",
    "        d[t] = d[t]* gamma + y\n",
    "    for t in team_test:\n",
    "        if t in d:\n",
    "            w_.append(d[t])\n",
    "        else:\n",
    "            w_.append(0)\n",
    "    return w, w_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "teams = list(set(train.team1))\n",
    "for i, weight_func in enumerate([lambda x: x**2, lambda x: x**3, lambda x: x**4,\n",
    "                                 lambda x: 1.01**x, lambda x: 1.05**x, lambda x: 1.1**x, lambda x: 1.2**x, \n",
    "                                 lambda x: np.log1p(x)**0.5, lambda x: np.log1p(x)**0.8, lambda x: np.log1p(x)**1, \n",
    "                                 lambda x: np.log1p(x)**1.2, lambda x: np.log1p(x)**1.5, lambda x: np.log1p(x)**2, \n",
    "                                 lambda x: np.log1p(x)**3, lambda x: np.log1p(x)**4, lambda x: 1.01**np.log1p(x), \n",
    "                                 lambda x: 1.05**np.log1p(x), lambda x: 1.1**np.log1p(x), lambda x: 1.2**np.log1p(x)]):\n",
    "    train['team1_mean' + str(i)] = 0\n",
    "    train['team2_mean' + str(i)] = 0\n",
    "    test['team1_mean' + str(i)] = 0\n",
    "    test['team2_mean' + str(i)] = 0\n",
    "    for t in teams:\n",
    "        y = train[train.team1 == t].target.values\n",
    "        w = weight_func(np.arange(len(y), 0, -1))\n",
    "        p = np.convolve(y, w)[:len(w)] * 1. / np.cumsum(w)\n",
    "        train.loc[train.team1 == t, 'team1_mean' + str(i)] = np.concatenate([[0.5], p[:-1]])\n",
    "        test.loc[test.team1 == t, 'team1_mean' + str(i)] = p[-1]\n",
    "    for t in teams:\n",
    "        y = 1 - train[train.team2 == t].target.values\n",
    "        w = weight_func(np.arange(len(y), 0, -1))\n",
    "        p = np.convolve(y, w)[:len(w)] * 1. / np.cumsum(w)\n",
    "        train.loc[train.team2 == t, 'team2_mean' + str(i)] = np.concatenate([[0.5], p[:-1]])\n",
    "        test.loc[test.team2 == t, 'team2_mean' + str(i)] = p[-1]\n",
    "    train['team1_mean_dif' + str(i)] = train['team1_mean' + str(i)].values - train['team2_mean' + str(i)].values\n",
    "    test['team1_mean_dif' + str(i)] = test['team1_mean' + str(i)].values - test['team2_mean' + str(i)].values\n",
    "    train = train.drop(['team1_mean' + str(i), 'team2_mean' + str(i)], axis=1)\n",
    "    test = test.drop(['team1_mean' + str(i), 'team2_mean' + str(i)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for g in [0.1, 0.05, 0.01, 0.005, 0.001]:\n",
    "    w1, w2, w1_, w2_ = history_rating(train.team1, train.team2, train.target, test.team1, test.team2, gamma=g)\n",
    "    g = str(g)\n",
    "    train['rating1_' + g], train['rating2_' + g] = w1, w2\n",
    "    test['rating1_' + g], test['rating2_' + g] = w1_, w2_\n",
    "    train['rating_dif_' + g] = train['rating1_' + g] - train['rating2_' + g]\n",
    "    #train['rating_rat_' + g] = train['rating1_' + g] / (train['rating1_' + g] + train['rating2_' + g])\n",
    "    test['rating_dif_' + g] = test['rating1_' + g] - test['rating2_' + g]\n",
    "    #test['rating_rat_' + g] = test['rating1_' + g] / (test['rating1_' + g] + test['rating2_' + g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for g in [0.95]:\n",
    "    w1, w2 = win_mean(train.team1, train.target, test.team1, gamma=g)\n",
    "    train['win1' + str(g)], test['win1' + str(g)] = w1, w2\n",
    "    w1, w2 = win_mean(train.team2, 1 - train.target, test.team2, gamma=g)\n",
    "    train['win2' + str(g)], test['win2' + str(g)] = w1, w2\n",
    "    train['win_dif' + str(g)] = train['win1' + str(g)] - train['win2' + str(g)]\n",
    "    test['win_dif' + str(g)] = test['win1' + str(g)] - test['win2' + str(g)]\n",
    "    train = train.drop(['win1' + str(g), 'win2' + str(g)], axis=1)\n",
    "    test = test.drop(['win1' + str(g), 'win2' + str(g)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([train, test])\n",
    "\n",
    "\n",
    "d = data.groupby(['year', 'team1']).mean()[['score1', 'score2']]\n",
    "d = d.reset_index().rename(columns={'score1': 'mean_score1_of_team1', 'score2': 'mean_score2_of_team1'})\n",
    "d.year += 2\n",
    "data = pd.merge(data, d, on=['year', 'team1'], how='left')\n",
    "\n",
    "d = data.groupby(['year', 'team2']).mean()[['score1', 'score2']]\n",
    "d = d.reset_index().rename(columns={'score1': 'mean_score1_of_team2', 'score2': 'mean_score2_of_team2'})\n",
    "d.year += 2\n",
    "data = pd.merge(data, d, on=['year', 'team2'], how='left')\n",
    "\n",
    "\n",
    "d = data.groupby(['year', 'team1']).std()[['score1', 'score2']]\n",
    "d = d.reset_index().rename(columns={'score1': 'std_score1_of_team1', 'score2': 'std_score2_of_team1'})\n",
    "d.year += 2\n",
    "data = pd.merge(data, d, on=['year', 'team1'], how='left')\n",
    "\n",
    "d = data.groupby(['year', 'team2']).std()[['score1', 'score2']]\n",
    "d = d.reset_index().rename(columns={'score1': 'std_score1_of_team2', 'score2': 'std_score2_of_team2'})\n",
    "d.year += 2\n",
    "data = pd.merge(data, d, on=['year', 'team2'], how='left')\n",
    "\n",
    "data['m1'] = data.mean_score1_of_team1 - data.mean_score1_of_team2\n",
    "data['m2'] = data.mean_score1_of_team1 - data.mean_score2_of_team1\n",
    "data['m3'] = data.mean_score1_of_team1 - data.mean_score2_of_team2\n",
    "data['m4'] = data.mean_score1_of_team2 - data.mean_score2_of_team1\n",
    "data['m5'] = data.mean_score1_of_team2 - data.mean_score2_of_team2\n",
    "data['m6'] = data.mean_score2_of_team1 - data.mean_score2_of_team2\n",
    "\n",
    "data['s1'] = data.std_score1_of_team1 - data.std_score1_of_team2\n",
    "data['s2'] = data.std_score1_of_team1 - data.std_score2_of_team1\n",
    "data['s3'] = data.std_score1_of_team1 - data.std_score2_of_team2\n",
    "data['s4'] = data.std_score1_of_team2 - data.std_score2_of_team1\n",
    "data['s5'] = data.std_score1_of_team2 - data.std_score2_of_team2\n",
    "data['s6'] = data.std_score2_of_team1 - data.std_score2_of_team2\n",
    "\n",
    "n = train.shape[0]\n",
    "train, test = data[:n], data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>day</th>\n",
       "      <th>linreg</th>\n",
       "      <th>logreg</th>\n",
       "      <th>rating1_0.001</th>\n",
       "      <th>rating1_0.005</th>\n",
       "      <th>rating1_0.01</th>\n",
       "      <th>rating1_0.05</th>\n",
       "      <th>rating1_0.1</th>\n",
       "      <th>rating2_0.001</th>\n",
       "      <th>...</th>\n",
       "      <th>m3</th>\n",
       "      <th>m4</th>\n",
       "      <th>m5</th>\n",
       "      <th>m6</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  day  linreg  logreg  rating1_0.001  rating1_0.005  rating1_0.01  \\\n",
       "0 NaN   19       0       0            0.5            0.5           0.5   \n",
       "1 NaN   19       0       0            0.5            0.5           0.5   \n",
       "2 NaN   28       0       0            0.5            0.5           0.5   \n",
       "3 NaN   28       0       0            0.5            0.5           0.5   \n",
       "4 NaN   28       0       0            0.5            0.5           0.5   \n",
       "\n",
       "   rating1_0.05  rating1_0.1  rating2_0.001 ...  m3  m4  m5  m6  s1  s2  s3  \\\n",
       "0           0.5          0.5            0.5 ... NaN NaN NaN NaN NaN NaN NaN   \n",
       "1           0.5          0.5            1.5 ... NaN NaN NaN NaN NaN NaN NaN   \n",
       "2           0.5          0.5            0.5 ... NaN NaN NaN NaN NaN NaN NaN   \n",
       "3           0.5          0.5            1.5 ... NaN NaN NaN NaN NaN NaN NaN   \n",
       "4           0.5          0.5            0.5 ... NaN NaN NaN NaN NaN NaN NaN   \n",
       "\n",
       "   s4  s5  s6  \n",
       "0 NaN NaN NaN  \n",
       "1 NaN NaN NaN  \n",
       "2 NaN NaN NaN  \n",
       "3 NaN NaN NaN  \n",
       "4 NaN NaN NaN  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dropcols = ['Id', 'day', 'score1', 'score2', 'year', 'target', 'year']\n",
    "rf = RandomForestClassifier(n_estimators=1000, max_depth=None, n_jobs=-1, random_state=0)\n",
    "rf.fit(train.drop(dropcols, axis=1).fillna(-1), train.target)\n",
    "pred_rf = rf.predict_proba(test.drop(dropcols, axis=1).fillna(-1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64481491371216493"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(test.target, pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.051256292856207079, 'win_dif0.95'),\n",
       " (-0.048217419622430237, 'team1_mean_dif4'),\n",
       " (-0.046526303308039765, 'team1_mean_dif5'),\n",
       " (-0.038154221736638648, 'team1_mean_dif6'),\n",
       " (-0.028742102539181812, 'team1_mean_dif3'),\n",
       " (-0.026277867161106843, 'team1_mean_dif2'),\n",
       " (-0.024082113925763624, 'rating2_0.01'),\n",
       " (-0.023569635469600506, 'rating2_0.001'),\n",
       " (-0.023546194472670104, 'rating2_0.005'),\n",
       " (-0.02350592688059501, 'team1_mean_dif1'),\n",
       " (-0.023475268957938458, 'rating2_0.1'),\n",
       " (-0.02329973119487553, 'rating2_0.05'),\n",
       " (-0.023286077001380329, 'linreg'),\n",
       " (-0.021478781511281436, 'rating_dif_0.001'),\n",
       " (-0.021444331166161731, 'rating_dif_0.005'),\n",
       " (-0.020159603138981488, 'team1_mean_dif0'),\n",
       " (-0.01992113901106848, 'rating_dif_0.01'),\n",
       " (-0.019104703525147433, 'team2'),\n",
       " (-0.019043656048740528, 'team1'),\n",
       " (-0.018473730859930704, 'rating_dif_0.05'),\n",
       " (-0.016619888214484371, 'team1_mean_dif14'),\n",
       " (-0.016079829127219461, 'rating_dif_0.1'),\n",
       " (-0.015273245431479629, 'logreg'),\n",
       " (-0.014804523555056265, 'team1_mean_dif13'),\n",
       " (-0.014095731611876675, 'std_score1_of_team2'),\n",
       " (-0.014066356389727292, 'std_score2_of_team2'),\n",
       " (-0.014027148636537199, 'std_score1_of_team1'),\n",
       " (-0.014006324061064473, 'mean_score2_of_team2'),\n",
       " (-0.013993437840181026, 'mean_score1_of_team2'),\n",
       " (-0.013963936469453063, 'std_score2_of_team1'),\n",
       " (-0.013910074112187105, 'mean_score1_of_team1'),\n",
       " (-0.013898219200478283, 'mean_score2_of_team1'),\n",
       " (-0.013865356290530657, 'team1_mean_dif12'),\n",
       " (-0.012955181452332706, 'team1_mean_dif10'),\n",
       " (-0.012947664169357616, 'team1_mean_dif18'),\n",
       " (-0.012523669732572858, 'm4'),\n",
       " (-0.012459850329079772, 'team1_mean_dif11'),\n",
       " (-0.012448273514929494, 'm6'),\n",
       " (-0.012427522061312299, 'm1'),\n",
       " (-0.012407670525024251, 'm3'),\n",
       " (-0.012395002827403686, 's4'),\n",
       " (-0.012335913685941398, 's3'),\n",
       " (-0.012324410899696563, 's1'),\n",
       " (-0.012311932739904033, 's6'),\n",
       " (-0.012191147057816177, 'team1_mean_dif15'),\n",
       " (-0.012174395990023236, 'team1_mean_dif7'),\n",
       " (-0.012139530314558004, 'team1_mean_dif9'),\n",
       " (-0.012121242383056655, 'team1_mean_dif16'),\n",
       " (-0.011987961458590981, 'team1_mean_dif8'),\n",
       " (-0.011743756447792462, 'team1_mean_dif17'),\n",
       " (-0.011697637850617382, 'rating1_0.1'),\n",
       " (-0.011436394863810703, 'rating1_0.001'),\n",
       " (-0.011317951469601781, 'rating1_0.01'),\n",
       " (-0.011249876534670949, 'rating1_0.05'),\n",
       " (-0.011150139629854654, 'rating1_0.005'),\n",
       " (-0.00027609882555242981, 's5'),\n",
       " (-0.00027336199537856214, 'm2'),\n",
       " (-0.00026717463090308879, 'm5'),\n",
       " (-0.00026706728220276084, 's2')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(-rf.feature_importances_, train.drop(dropcols, axis=1).columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "d1, d1_ = ohe.fit_transform(train[['team1']]), ohe.transform(test[['team1']])\n",
    "d2, d2_ = ohe.fit_transform(train[['team2']]), ohe.transform(test[['team2']])\n",
    "lr = LogisticRegression(C=0.24)\n",
    "n = 70000\n",
    "lr.fit((d1 - d2)[-n:], train.target[-n:])\n",
    "pred_lr = lr.predict_proba(d1_ - d2_)[:,1]\n",
    "#log_loss(test.target, pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 0.6064370169725547)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [log_loss(test.target, pred_lr**w * pred_rf**(1 - w)) for w in np.linspace(0, 1, 101)]\n",
    "np.argmin(x), np.min(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72578"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "192578 - 120000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for C in np.linspace(0.1, 0.5, 21):\n",
    "    for n in [50000, 60000, 70000, 80000, 90000, 100000]:\n",
    "        lr.fit((d1 - d2)[-n:], train.target[-n:])\n",
    "        pred_lr = lr.predict_proba(d1_ - d2_)[:,1]\n",
    "        score = log_loss(test.target, pred_lr)\n",
    "        scores.append((score, n, C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1 ,  0.12,  0.14,  0.16,  0.18,  0.2 ,  0.22,  0.24,  0.26,\n",
       "        0.28,  0.3 ,  0.32,  0.34,  0.36,  0.38,  0.4 ,  0.42,  0.44,\n",
       "        0.46,  0.48,  0.5 ])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0.1, 0.5, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = test.Id.notnull().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = 0.7\n",
    "pred = pred_lr**w * pred_rf**(1 - w)\n",
    "pd.DataFrame({'Id': test[ind].Id.astype(int), 'target': pred[ind]}).to_csv('subm.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Id.notnull().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
